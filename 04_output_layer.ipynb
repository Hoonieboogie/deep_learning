{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c32a90",
   "metadata": {},
   "source": [
    "# 출력층 설계 (Output Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c22e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\anaconda3\\envs\\torch_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------- -------------- 5/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ------------------------------ --------- 6/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchaudio]\n",
      "   ----------------------------------- ---- 7/8 [torchaudio]\n",
      "   ---------------------------------------- 8/8 [torchaudio]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cacdf4b",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07856dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "# How? 비율은 똑같이 유지가 되니까 이런 계산식 적용이 가능 \n",
    "def stable_softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z)) # Overflow prevention\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "\n",
    "x = np.array([1000, 1001, 1002])\n",
    "# print(softmax(x)) # This causes overflow by e^z exceeding the max limit -> calculation error\n",
    "print(stable_softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77da133",
   "metadata": {},
   "source": [
    "- pythorch 라이브러리 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539f5552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor([1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mz/fktgp6vj62l5dw84vjcg4zj40000gn/T/ipykernel_29479/3246280021.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_output = F.softmax(x) # torch에서 제공하는 overflow 없는 stable한 softmax (torch의 tensor 타입만 가능, torch의 float만 가능)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([1000, 1001, 1002], dtype = torch.float32) # pytorch식 텐서 만들기\n",
    "\n",
    "softmax_output = F.softmax(x) # torch에서 제공하는 overflow 없는 stable한 softmax (torch의 tensor 타입만 가능, torch의 float만 가능)\n",
    "print(softmax_output)\n",
    "\n",
    "# pytorch에서 sigmoid는 functional 말고 torch에 있음\n",
    "sigmoid_output = torch.sigmoid(x)\n",
    "print(sigmoid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37bc97",
   "metadata": {},
   "source": [
    "### 손실 함수와 연계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23401327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2759089469909668\n",
      "1.238755702972412\n",
      "1.2023335695266724\n",
      "1.1666080951690674\n",
      "1.1315937042236328\n",
      "1.0973193645477295\n",
      "1.06381094455719\n",
      "1.0310912132263184\n",
      "0.9991796612739563\n",
      "0.9680922031402588\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# 간단한 다중 클래스 분류 모델 정의\n",
    "class SimpleMultiClassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMultiClassModel, self).__init__()\n",
    "        self.fc = nn.Linear(5,3) # fc = fully connected, Linear는 선형 계산 층 말하는 것 -> (5,3) 5개의 입력 받아서 3개의 출력\n",
    "\n",
    "    # 순전파, scikit-learn에서 .predict 같은 기능\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "model = SimpleMultiClassModel()\n",
    "criterion = nn.CrossEntropyLoss() # 손실함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # 가중치 최적화 함수 (adam) 정의\n",
    "\n",
    "inputs = torch.randn(4,5) # (4,5) shape으로 표준 정규분포 형태 따르는 난수 생성\n",
    "labels = torch.tensor([0, 2, 1, 0])\n",
    "\n",
    "# 가중치 업데이트 시키면서 손실값이 줄어드는 것 확인\n",
    "for _ in range(10):\n",
    "    preds = model(inputs) # 순전파\n",
    "    loss = criterion(preds, labels) # 손실계산\n",
    "    print(loss.item())\n",
    "\n",
    "    optimizer.zero_grad() # 기울기 초기화 (이전 단계에서 계산된 기울기를 0으로 초기화)\n",
    "    loss.backward() # 역전파 (손실에 대한 역전파 수행 - 파라미터에 대한 기울기 계산)\n",
    "    optimizer.step() # 가중치 업데이트 (계산된 기울기를 사용하여 옵티마이저가 모델 파라미터 갱신)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
